# configs/components.yaml
selectors:
  # 动态数据选择器
  nice:
    name: nice
    params:
      cache_dir: ../dataflex_saves/nice_output
      gradient_type: adam
      proj_dim: 4096
      seed: 123
      component_overrides:
      # Policy model and trained model set to the same model is the NICE algorithm in paper, different is the NICEAMC algorithm in paper.
      policy_model_path: /path/to/your/policy_model        
      # Use a strong model, preferably different from policy series.
      reward_model_path: /path/to/your/judge_model    
      mc_samples: 4
      max_new_tokens: 512
      generation_temperature: 0.7
      max_prompt_length: 4096

  less:
    name: less
    params:
      cache_dir: ../dataflex_saves/less_output
      gradient_type: adam
      proj_dim: 4096
      seed: 123

  loss:
    name: loss
    params:
      cache_dir: ../dataflex_saves/loss_output
      focus: "medium"

  delta_loss:
    name: delta_loss
    params:
      cache_dir: ../dataflex_saves/delta_loss_output
      window_size: 0.2
  tsds:
    name: tsds
    params:
      max_K: 128
      kde_K: 64
      sigma: 0.8
      alpha: 0.5
      C: 10.0
      model_name: "/home/lianghao/yry/TSDS/bert_chinese"
      cache_dir: ../dataflex_saves/tsds_output
      
  custom:
    name: custom
    params:
      cache_dir: ../dataflex_saves/custom_output

mixers:
  # 动态数据混合器
  random:
    name: random
    params:
      seed: 42

weighters:
  # 动态数据加权器
  loss:
    name: loss
    params:
      strategy: linupper # choices: [linupper, uniform, quadratic, extremes]
      delta: 1.0
  
  custom:
    name: custom
    params:
      strategy: uniform
